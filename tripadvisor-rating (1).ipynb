{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.pata.org/wp-content/uploads/2014/09/TripAdvisor_Logo-300x119.png)\n",
    "# Predict TripAdvisor Rating\n",
    "## В этом соревновании нам предстоит предсказать рейтинг ресторана в TripAdvisor\n",
    "**По ходу задачи:**\n",
    "* Прокачаем работу с pandas\n",
    "* Научимся работать с Kaggle Notebooks\n",
    "* Поймем как делать предобработку различных данных\n",
    "* Научимся работать с пропущенными данными (Nan)\n",
    "* Познакомимся с различными видами кодирования признаков\n",
    "* Немного попробуем [Feature Engineering](https://ru.wikipedia.org/wiki/Конструирование_признаков) (генерировать новые признаки)\n",
    "* И совсем немного затронем ML\n",
    "* И многое другое...   \n",
    "\n",
    "\n",
    "\n",
    "### И самое важное, все это вы сможете сделать самостоятельно!\n",
    "\n",
    "*Этот Ноутбук являетсся Примером/Шаблоном к этому соревнованию (Baseline) и не служит готовым решением!*   \n",
    "Вы можете использовать его как основу для построения своего решения.\n",
    "\n",
    "> что такое baseline решение, зачем оно нужно и почему предоставлять baseline к соревнованию стало важным стандартом на kaggle и других площадках.   \n",
    "**baseline** создается больше как шаблон, где можно посмотреть как происходит обращение с входящими данными и что нужно получить на выходе. При этом МЛ начинка может быть достаточно простой, просто для примера. Это помогает быстрее приступить к самому МЛ, а не тратить ценное время на чисто инженерные задачи. \n",
    "Также baseline являеться хорошей опорной точкой по метрике. Если твое решение хуже baseline - ты явно делаешь что-то не то и стоит попробовать другой путь) \n",
    "\n",
    "В контексте нашего соревнования baseline идет с небольшими примерами того, что можно делать с данными, и с инструкцией, что делать дальше, чтобы улучшить результат.  Вообще готовым решением это сложно назвать, так как используются всего 2 самых простых признака (а остальные исключаются)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "import re\n",
    "\n",
    "# Загружаем специальный удобный инструмент для разделения датасета:\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n",
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\n",
    "df_train = pd.read_csv(DATA_DIR+'/main_task.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\n",
    "sample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подробнее по признакам:\n",
    "* City: Город \n",
    "* Cuisine Style: Кухня\n",
    "* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n",
    "* Price Range: Цены в ресторане в 3 категориях\n",
    "* Number of Reviews: Количество отзывов\n",
    "* Reviews: 2 последних отзыва и даты этих отзывов\n",
    "* URL_TA: страница ресторана на 'www.tripadvisor.com' \n",
    "* ID_TA: ID ресторана в TripAdvisor\n",
    "* Rating: Рейтинг ресторана"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Переименуем для удобства колонки \n",
    "data.columns = [\"restaurant_id\", \"city\", \"cuisine\", \"ranking\", \"price\", \"number_of_reviews\",\n",
    "              \"reviews\", \"URL\", \"ID\", \"sample\", \"Rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Первоначальный просмотр общих значений.\n",
    "def viewing(column):\n",
    "    print('') \n",
    "    print('Столбец', column)\n",
    "    display(data[column].value_counts())\n",
    "    print('Количество пропусков: {}'.format(data[column].isnull().sum()), \n",
    "          'Количество уникальных значений: {}'.format(data[column].nunique()), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим функцию для получения интересующих нас параметров\n",
    "def quantity_check(column):\n",
    "    ab_25perc = data[column].quantile(0.25, interpolation=\"midpoint\")\n",
    "    ab_75perc = data[column].quantile(0.75, interpolation=\"midpoint\")\n",
    "    ab_IQR = ab_75perc-ab_25perc\n",
    "    print('Q1:{}'.format(ab_25perc), 'Q3:{}'.format(ab_75perc), 'IQR:{}'.format(ab_IQR),\n",
    "          'Граница выбросов: [{a},{b}]'.format(a=ab_25perc-1.5*ab_IQR, b=ab_75perc+1.5*ab_IQR), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewing('restaurant_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, какие рестораны сетевые, а какие нет. И заполним 1 или 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим переменную для сетевых ресторанов.\n",
    "chain = list(data.restaurant_id.value_counts()[data.restaurant_id.value_counts() > 1].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим новую колонку для наших ресторанов.\n",
    "data['chain_restaurant'] = data[data.restaurant_id.isin(chain)].restaurant_id.apply(lambda x: 1)\n",
    "data['chain_restaurant'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewing('city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "sns.boxplot(x='city', y='Rating', data=data[data['sample'] == 1])\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['City'].value_counts(ascending=True).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что выделяются 4 города: Милан, Рим, Лондон, Париж.\n",
    "Милан - рейтинг до 4.5. У остальных до 5.0 Милан где-то не дотягивает. Странно...\n",
    "Рим - рейтинг от 3.0. Значит, что Кухня людей устраивает. Можно туда ехать и не бояться, что что-то будет не так.)))\n",
    "Лондон и Париж - два города с самым большим кол-вом ресторанов. Но в Лондоне всё-таки их больше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заменяем ошибочное название города Порту на правильное. По Копенгагену и Мюнхену вопрос...\n",
    "# но в целом принять можно.\n",
    "data.loc[data.city == 'Oporto', 'city'] = 'Porto'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Население городов\n",
    "population = {\n",
    "            'Paris': 2148327,\n",
    "            'Stockholm': 961609,\n",
    "            'London': 8908081,\n",
    "            'Berlin': 3644826,\n",
    "            'Munich': 1471508,\n",
    "            'Porto': 237591,\n",
    "            'Milan': 1378689,\n",
    "            'Bratislava': 437725,\n",
    "            'Vienna': 1897491,\n",
    "            'Rome': 2870500,\n",
    "            'Barcelona': 1636762,\n",
    "            'Madrid': 3266126,\n",
    "            'Dublin': 1173179,\n",
    "            'Brussels': 179277,\n",
    "            'Zurich': 428737,\n",
    "            'Warsaw': 1790658,\n",
    "            'Budapest': 1752286,\n",
    "            'Copenhagen': 615993,\n",
    "            'Amsterdam': 872757,\n",
    "            'Lyon': 506615,\n",
    "            'Hamburg': 1841179,\n",
    "            'Lisbon': 505526,\n",
    "            'Prague': 1301132,\n",
    "            'Oslo': 673469,\n",
    "            'Helsinki': 655281,\n",
    "            'Edinburgh': 488100,\n",
    "            'Geneva': 200548,\n",
    "            'Ljubljana': 284355,\n",
    "            'Athens': 664046,\n",
    "            'Luxembourg': 115227,\n",
    "            'Krakow': 779115\n",
    "        }\n",
    "data['population'] = data['city'].map(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Количество ресторанов в городе\n",
    "rest_count_dict = dict(data['city'].value_counts())\n",
    "data['rest_count'] = data['city'].map(rest_count_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Относительный рейтинг по городу\n",
    "data['ranking_per_city'] = data['ranking'] / data['rest_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задаём столицы и выводим 1 или 0\n",
    "Capitals = ['London', 'Paris', 'Madrid', 'Berlin', 'Rome', 'Prague', 'Lisbon', 'Vienna', 'Amsterdam', 'Brussels', 'Stockholm',\n",
    "            'Budapest', 'Warsaw', 'Dublin', 'Copenhagen', 'Athens', 'Edinburgh', 'Oslo', 'Helsinki', 'Bratislava', 'Luxemburg', 'Ljubljana']\n",
    "data['capital'] = data['city'].apply(lambda x: 1 if x in Capitals else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['not_capital'] = data['capital'].apply(lambda x: 1 if x == 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Площадь городов (кв.км)\n",
    "square_area = {'Amsterdam': 219, 'Athens': 412, 'Barcelona': 101, 'Berlin': 891, 'Bratislava': 368, 'Brussels': 32.6,\n",
    "        'Budapest': 525, 'Copenhagen': 86.4, 'Dublin': 115, 'Edinburgh': 175, 'Geneva': 15.9, 'Hamburg': 755,\n",
    "        'Helsinki': 715, 'Krakow': 327, 'Lisbon': 100, 'Ljubljana': 163, 'London': 1706, 'Luxembourg': 51.5,\n",
    "        'Lyon': 47.9, 'Madrid': 607, 'Milan': 181, 'Munich': 310, 'Porto': 41.7, 'Oslo': 454, 'Paris': 105,\n",
    "        'Prague': 496, 'Rome': 1287, 'Stockholm': 188, 'Vienna': 414, 'Warsaw': 517, 'Zurich': 91.9}\n",
    "data['square_area'] = data['city'].map(square_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создали 3 новые колонки на основе информации о городах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewing('cuisine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поработаем с кухнями и выберем 50 самых непопулярных и 50 самых популярных. Заменим пропуски на \"Other\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого создадим 2 переменные и 2 функции, а также на основании этого 2 новые колонки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cuisine'] = data['cuisine'].apply(lambda x: re.findall(r\"'(\\b.*?\\b)'\", str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_low_lst = data.explode('cuisine')['cuisine'].value_counts()[\n",
    "    data.explode('cuisine')['cuisine'].value_counts() < 50].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuisine_low_count(cell):\n",
    "    x = 0\n",
    "    for i in cuisine_low_lst:\n",
    "        if i in cell:\n",
    "            x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['low_cuisine'] = data['cuisine'].apply(cuisine_low_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisine_high_lst = data.explode('cuisine')['cuisine'].value_counts()[\n",
    "    data.explode('cuisine')['cuisine'].value_counts() > 50].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cuisine_high_count(cell):\n",
    "    x = 0\n",
    "    for i in cuisine_high_lst:\n",
    "        if i in cell:\n",
    "            x += 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['high_cuisine'] = data['cuisine'].apply(cuisine_high_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cuisine'].fillna(\"['Other']\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим кол-во кухонь и сделаем топ 10 кухонь по версии моей мамы))) И оформим в 10 новых колонок + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cuisine_x = data['cuisine']\n",
    "Cuisine_number = Cuisine_x.explode() \n",
    "\n",
    "Cuisine_number.value_counts().head(50).plot(kind='bar', title='cuisine')\n",
    "Cuisine_number.value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В колонке есть данные, не соответствующие этой колонке (на мой взгляд), например Cafe, Pub и т.д. (это же заведение, а не кухня (может конечно подразумеваться кухня в этих заведениях?), тем не менее это значение вызывает много вопросов), а удалить строку по условию нельзя, только колонку. Поэтому сложно принять решение что нужно, при составлении отдельных топ 10 колонок. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 топовых типов кухонь\n",
    "def c0(rec):\n",
    "    if type(rec)==float:\n",
    "        return 0\n",
    "    elif 'Vegetarian Friendly' in rec or 'Vegan Options' in rec or 'Gluten Free Options'in rec:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['Vegetarian']=data['cuisine'].apply(c0)\n",
    "\n",
    "def c1(rec):\n",
    "    if type(rec)==float:\n",
    "        return 0\n",
    "    elif 'European' in rec:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['European']=data['cuisine'].apply(c1)\n",
    "\n",
    "def c2(rec):\n",
    "    if type(rec)==float:\n",
    "        return 0\n",
    "    elif 'Mediterranean' in rec:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['Mediterranean']=data['cuisine'].apply(c2)\n",
    "\n",
    "def c3(rec):\n",
    "    if type(rec)==float:\n",
    "        return 0\n",
    "    elif 'Italian' in rec or 'Pizza' in rec:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['Italian']=data['cuisine'].apply(c3)\n",
    "\n",
    "def c4(rec):\n",
    "    if type(rec)==float:\n",
    "        return 0\n",
    "    elif 'Pub' in rec or 'Bar' in rec or 'Wine Bar' in rec or 'Cafe' in rec:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['Bar']=data['cuisine'].apply(c4)\n",
    "\n",
    "def c5(rec):\n",
    "    if type(rec)==float:\n",
    "        return 0\n",
    "    elif 'French' in rec:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['French']=data['cuisine'].apply(c5)\n",
    "\n",
    "def c6(rec):\n",
    "    if type(rec)==float:\n",
    "        return 0\n",
    "    elif 'Asian' in rec:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['Asian']=data['cuisine'].apply(c6)\n",
    "\n",
    "def c7(rec):\n",
    "    if type(rec)==float:\n",
    "        return 0\n",
    "    elif 'Spanish' in rec:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['Spanish']=data['cuisine'].apply(c7)\n",
    "\n",
    "def c8(rec):\n",
    "    if type(rec)==float:\n",
    "        return 0\n",
    "    elif 'American' in rec or 'Fast Food' in rec:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['American']=data['cuisine'].apply(c8)\n",
    "\n",
    "def c9(rec):\n",
    "    if type(rec)==float:\n",
    "        return 0\n",
    "    elif 'Japanese' in rec or 'Seafood' in rec or 'Sushi' in rec:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "data['Japanese']=data['cuisine'].apply(c9)\n",
    "\n",
    "def c10(rec):\n",
    "    if type(rec)==float:\n",
    "        return 0\n",
    "    elif 'Vegetarian Friendly' in rec or 'Vegan Options' in rec or 'Gluten Free Options' in rec or 'Japanese' in rec or 'Seafood' in rec or 'Sushi' in rec or 'American' in rec or 'Fast Food' in rec or 'Spanish' in rec or 'Asian' in rec or 'French' in rec or 'Pub' in rec or 'Bar' in rec or 'Wine Bar' in rec or 'Italian' in rec or 'Pizza' in rec or 'Mediterranean' in rec or 'European' in rec:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "data['Other_cuisine']=data['cuisine'].apply(c10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewing('ranking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на топ 10 городов\n",
    "for x in (data['city'].value_counts())[0:10].index:\n",
    "    data['ranking'][data['city'] == x].hist(bins=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что Ranking имеет нормальное распределение, просто в больших городах больше ресторанов, из-за этого мы имеем смещение. Разделим Ranking на количество ресторанов в городе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим минимальный, средний и максимальный ранг для городов. И запишем их в новые колонки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Минимальный ранг по городу \n",
    "min_city_ranking = dict(data.groupby(['city'])['ranking'].min())\n",
    "data['Min_ranking'] = data['city'].map(min_city_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средний ранг по городу \n",
    "mean_city_ranking = dict(data.groupby(['city'])['ranking'].mean())\n",
    "data['Mean_ranking'] = data['city'].map(mean_city_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Максимальный ранг по городу \n",
    "max_city_ranking = dict(data.groupby(['city'])['ranking'].max())\n",
    "data['Max_ranking'] = data['city'].map(max_city_ranking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewing('Rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewing('price')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пропуски можем заполнить самым популярным значением.\n",
    "data['price'] = data['price'].fillna('$$ - $$$')\n",
    "\n",
    "# Меняем значения на цифровой вариант.\n",
    "replace_price_range = {'$': 1, '$$ - $$$': 2, '$$$$':4}\n",
    "data['price'] = data['price'].map(replace_price_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хотя из-за того, что пропущенных значений много, можно было бы и подумать как их можно ещё распределить. Но мыслей пока нет, может потом появятся. Должны появиться)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewing('number_of_reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Number_of_Reviews_isNAN'] = pd.isna(data['number_of_reviews']).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним пропущенные значения средним по городу.\n",
    "data['number_of_reviews'] = data.groupby(\"city\")['number_of_reviews'].transform(\n",
    "    lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewing('reviews')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колонку reviews с отзывами я удалю. Почему? По 2-3 отзыва с разбросанными датами...этого очень мало. Надо парсить отзывы, но я к сожалению пока это не проходил, а времени на изучение парсинга нет((( Поэтому это всё в другой раз))) Т.е. в следующий заход)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewing('URL')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной колонке вижу только названия ресторанов. Всё остальное не выглядит как полезные данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выносим названия ресторанов из колонки URL\n",
    "data['URL'] = data['URL'].str.split('-')\n",
    "# Приводим к единому регистру.\n",
    "data['URL'] = [x[4].lower() for x in data['URL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посмотрим кол-во ресторанов и выведим 50 из них.\n",
    "Cuisine_x = data['URL']\n",
    "Cuisine_number = Cuisine_x.explode() \n",
    "\n",
    "Cuisine_number.value_counts().head(50).plot(kind='bar', title='Restaurans')\n",
    "Cuisine_number.value_counts().head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Макдональдс больше всех в разы. Совпадение? Не думаю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмём рестораны, где их кол-во более 2. И заполним 1 и 0.\n",
    "URL_limit = 2\n",
    "URL_cnts = Cuisine_number.value_counts()\n",
    "URL_columns = list(URL_cnts[URL_cnts > URL_limit].index)\n",
    "Other_columns = list(set(URL_cnts.index) - set(URL_columns))\n",
    "    \n",
    "# И соответственно заменим на 1 или 0.\n",
    "for URL in URL_columns:\n",
    "    data[URL] = data['URL'].astype(\n",
    "            'str').apply(lambda x: 1 if URL in x else 0)\n",
    "\n",
    "\n",
    "def other_URL(URL_str):\n",
    "    for URL in Other_columns:\n",
    "        if URL in URL_str:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewing('ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. колонки restaurant_id и ID одинаковы. Забегая наперёд, restaurant_id мы удалим, а из ID достанем идентификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ID'] = data['ID'].apply(lambda x: int(x[1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим корреляцию**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (15,10)\n",
    "sns.heatmap(data.drop(['sample'], axis=1).corr(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем ненужные колонки.\n",
    "data=data.drop(['restaurant_id', 'reviews'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для One-Hot Encoding в pandas есть готовая функция - get_dummies.\n",
    "data = pd.get_dummies(data, columns=['city'], dummy_na=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если так, то почему бы и не применить)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Теперь, для удобства и воспроизводимости кода, завернем всю обработку в одну большую функцию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# на всякий случай, заново подгружаем данные\n",
    "\n",
    "df_train = pd.read_csv(DATA_DIR+'/main_task.csv')\n",
    "df_test = pd.read_csv(DATA_DIR+'/kaggle_task.csv')\n",
    "df_train['sample'] = 1 # помечаем где у нас трейн\n",
    "df_test['sample'] = 0 # помечаем где у нас тест\n",
    "df_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n",
    "\n",
    "data = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_data(df_input):\n",
    "    '''includes several functions to pre-process the predictor data.'''\n",
    "    \n",
    "    df_output = df_input.copy()\n",
    "    \n",
    "    # ################### 1. Предобработка ############################################################## \n",
    "    \n",
    "    \n",
    "    # \n",
    "    def viewing(column):\n",
    "        print('') \n",
    "        print('Столбец', column)\n",
    "        display(df_output[column].value_counts())\n",
    "        print('Количество пропусков: {}'.format(df_output[column].isnull().sum()), \n",
    "              'Количество уникальных значений: {}'.format(df_output[column].nunique()), sep='\\n')\n",
    "        \n",
    "    # \n",
    "    def quantity_check(column):\n",
    "        ab_25perc = data[column].quantile(0.25, interpolation=\"midpoint\")\n",
    "        ab_75perc = data[column].quantile(0.75, interpolation=\"midpoint\")\n",
    "        ab_IQR = ab_75perc-ab_25perc\n",
    "        print('Q1:{}'.format(ab_25perc), 'Q3:{}'.format(ab_75perc), 'IQR:{}'.format(ab_IQR),\n",
    "              'Граница выбросов: [{a},{b}]'.format(a=ab_25perc-1.5*ab_IQR, b=ab_75perc+1.5*ab_IQR), sep='\\n')    \n",
    "\n",
    "        \n",
    "    #  \n",
    "    df_output.columns = [\"restaurant_id\", \"city\", \"cuisine\", \"ranking\", \"price\", \"number_of_reviews\",\n",
    "                  \"reviews\", \"URL\", \"ID\", \"sample\", \"Rating\"]\n",
    "    \n",
    "    # \n",
    "    chain = list(df_output.restaurant_id.value_counts()[df_output.restaurant_id.value_counts() > 1].index)\n",
    "    # \n",
    "    df_output['chain_restaurant'] = df_output[df_output.restaurant_id.isin(chain)].restaurant_id.apply(lambda x: 1)\n",
    "    df_output['chain_restaurant'].fillna(0, inplace=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # \n",
    "    df_output.loc[df_output.city == 'Oporto', 'city'] = 'Porto'\n",
    "    \n",
    "    # \n",
    "    population = {\n",
    "            'Paris': 2148327,\n",
    "            'Stockholm': 961609,\n",
    "            'London': 8908081,\n",
    "            'Berlin': 3644826,\n",
    "            'Munich': 1471508,\n",
    "            'Porto': 237591,\n",
    "            'Milan': 1378689,\n",
    "            'Bratislava': 437725,\n",
    "            'Vienna': 1897491,\n",
    "            'Rome': 2870500,\n",
    "            'Barcelona': 1636762,\n",
    "            'Madrid': 3266126,\n",
    "            'Dublin': 1173179,\n",
    "            'Brussels': 179277,\n",
    "            'Zurich': 428737,\n",
    "            'Warsaw': 1790658,\n",
    "            'Budapest': 1752286,\n",
    "            'Copenhagen': 615993,\n",
    "            'Amsterdam': 872757,\n",
    "            'Lyon': 506615,\n",
    "            'Hamburg': 1841179,\n",
    "            'Lisbon': 505526,\n",
    "            'Prague': 1301132,\n",
    "            'Oslo': 673469,\n",
    "            'Helsinki': 655281,\n",
    "            'Edinburgh': 488100,\n",
    "            'Geneva': 200548,\n",
    "            'Ljubljana': 284355,\n",
    "            'Athens': 664046,\n",
    "            'Luxembourg': 115227,\n",
    "            'Krakow': 779115\n",
    "        }\n",
    "    df_output['population'] = df_output['city'].map(population)\n",
    "    \n",
    "    \n",
    "    #\n",
    "    rest_count_dict = dict(df_output['city'].value_counts())\n",
    "    df_output['rest_count'] = df_output['city'].map(rest_count_dict)\n",
    "    \n",
    "    # \n",
    "    df_output['ranking_per_city'] = df_output['ranking'] / df_output['rest_count']\n",
    "    \n",
    "    \n",
    "    # \n",
    "    Capitals = ['London', 'Paris', 'Madrid', 'Berlin', 'Rome', 'Prague', 'Lisbon', 'Vienna', 'Amsterdam', 'Brussels', 'Stockholm',\n",
    "                'Budapest', 'Warsaw', 'Dublin', 'Copenhagen', 'Athens', 'Edinburgh', 'Oslo', 'Helsinki', 'Bratislava', 'Luxemburg', 'Ljubljana']\n",
    "    df_output['capital'] = df_output['city'].apply(lambda x: 1 if x in Capitals else 0)\n",
    "    \n",
    "    df_output['not_capital'] = df_output['capital'].apply(lambda x: 1 if x == 0 else 0)\n",
    "    \n",
    "    \n",
    "    # \n",
    "    square_area = {'Amsterdam': 219, 'Athens': 412, 'Barcelona': 101, 'Berlin': 891, 'Bratislava': 368, 'Brussels': 33,\n",
    "            'Budapest': 525, 'Copenhagen': 87, 'Dublin': 115, 'Edinburgh': 118, 'Geneva': 16, 'Hamburg': 755,\n",
    "            'Helsinki': 715, 'Krakow': 327, 'Lisbon': 100, 'Ljubljana': 163, 'London': 1706, 'Luxembourg': 52,\n",
    "            'Lyon': 48, 'Madrid': 607, 'Milan': 181, 'Munich': 310, 'Porto': 42, 'Oslo': 454, 'Paris': 105,\n",
    "            'Prague': 496, 'Rome': 1287, 'Stockholm': 188, 'Vienna': 414, 'Warsaw': 517, 'Zurich': 92}\n",
    "    df_output['square_area'] = df_output['city'].map(square_area)\n",
    "    \n",
    "    \n",
    "    \n",
    "    df_output['cuisine'] = df_output['cuisine'].apply(lambda x: re.findall(r\"'(\\b.*?\\b)'\", str(x)))\n",
    "    df_output['Cuisine_Style_isNAN'] = pd.isna(df_output['cuisine']).astype('uint8')\n",
    "    cuisine_low_lst = df_output.explode('cuisine')['cuisine'].value_counts()[\n",
    "    df_output.explode('cuisine')['cuisine'].value_counts() < 50].index.tolist()\n",
    "    \n",
    "    def cuisine_low_count(cell):\n",
    "        x = 0\n",
    "        for i in cuisine_low_lst:\n",
    "            if i in cell:\n",
    "                x += 1\n",
    "        return x\n",
    "\n",
    "    df_output['low_cuisine'] = df_output['cuisine'].apply(cuisine_low_count)\n",
    "    \n",
    "    cuisine_high_lst = df_output.explode('cuisine')['cuisine'].value_counts()[\n",
    "    df_output.explode('cuisine')['cuisine'].value_counts() > 50].index.tolist()\n",
    "    \n",
    "    def cuisine_high_count(cell):\n",
    "        x = 0\n",
    "        for i in cuisine_high_lst:\n",
    "            if i in cell:\n",
    "                x += 1\n",
    "        return x\n",
    "\n",
    "    df_output['high_cuisine'] = df_output['cuisine'].apply(cuisine_high_count)\n",
    "    \n",
    "    df_output['cuisine'].fillna(\"['Other']\", inplace=True) \n",
    "    \n",
    "\n",
    "        # \n",
    "    def c0(rec):\n",
    "        if type(rec)==float:\n",
    "            return 0\n",
    "        elif 'Vegetarian Friendly' in rec or 'Vegan Options' in rec or 'Gluten Free Options'in rec:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df_output['Vegetarian']=df_output['cuisine'].apply(c0)\n",
    "\n",
    "    def c1(rec):\n",
    "        if type(rec)==float:\n",
    "            return 0\n",
    "        elif 'European' in rec:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df_output['European']=df_output['cuisine'].apply(c1)\n",
    "\n",
    "    def c2(rec):\n",
    "        if type(rec)==float:\n",
    "            return 0\n",
    "        elif 'Mediterranean' in rec:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df_output['Mediterranean']=df_output['cuisine'].apply(c2)\n",
    "\n",
    "    def c3(rec):\n",
    "        if type(rec)==float:\n",
    "            return 0\n",
    "        elif 'Italian' in rec or 'Pizza' in rec:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df_output['Italian']=df_output['cuisine'].apply(c3)\n",
    "\n",
    "    def c4(rec):\n",
    "        if type(rec)==float:\n",
    "            return 0\n",
    "        elif 'Pub' in rec or 'Bar' in rec or 'Wine Bar' in rec or 'Cafe' in rec:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df_output['Bar']=df_output['cuisine'].apply(c4)\n",
    "\n",
    "    def c5(rec):\n",
    "        if type(rec)==float:\n",
    "            return 0\n",
    "        elif 'French' in rec:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df_output['French']=df_output['cuisine'].apply(c5)\n",
    "\n",
    "    def c6(rec):\n",
    "        if type(rec)==float:\n",
    "            return 0\n",
    "        elif 'Asian' in rec:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df_output['Asian']=df_output['cuisine'].apply(c6)\n",
    "\n",
    "    def c7(rec):\n",
    "        if type(rec)==float:\n",
    "            return 0\n",
    "        elif 'Spanish' in rec:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df_output['Spanish']=df_output['cuisine'].apply(c7)\n",
    "\n",
    "    def c8(rec):\n",
    "        if type(rec)==float:\n",
    "            return 0\n",
    "        elif 'American' in rec or 'Fast Food' in rec:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df_output['American']=df_output['cuisine'].apply(c8)\n",
    "\n",
    "    def c9(rec):\n",
    "        if type(rec)==float:\n",
    "            return 0\n",
    "        elif 'Japanese' in rec or 'Seafood' in rec or 'Sushi' in rec:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df_output['Japanese']=df_output['cuisine'].apply(c9)\n",
    "\n",
    "    def c10(rec):\n",
    "        if type(rec)==float:\n",
    "            return 0\n",
    "        elif 'Vegetarian Friendly' in rec or 'Vegan Options' in rec or 'Gluten Free Options' in rec or 'Japanese' in rec or 'Seafood' in rec or 'Sushi' in rec or 'American' in rec or 'Fast Food' in rec or 'Spanish' in rec or 'Asian' in rec or 'French' in rec or 'Pub' in rec or 'Bar' in rec or 'Wine Bar' in rec or 'Italian' in rec or 'Pizza' in rec or 'Mediterranean' in rec or 'European' in rec:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    df_output['Other_cuisine']=df_output['cuisine'].apply(c10)\n",
    "\n",
    "    \n",
    "        \n",
    "    # \n",
    "    min_city_ranking = dict(df_output.groupby(['city'])['ranking'].min())\n",
    "    df_output['Min_ranking'] = df_output['city'].map(min_city_ranking)\n",
    "    \n",
    "    # \n",
    "    mean_city_ranking = dict(df_output.groupby(['city'])['ranking'].mean())\n",
    "    df_output['Mean_ranking'] = df_output['city'].map(mean_city_ranking)\n",
    "    \n",
    "    # \n",
    "    max_city_ranking = dict(df_output.groupby(['city'])['ranking'].max())\n",
    "    df_output['Max_ranking'] = df_output['city'].map(max_city_ranking)\n",
    "    \n",
    "    \n",
    "    # \n",
    "    df_output['price'] = df_output['price'].fillna('$$ - $$$')\n",
    "\n",
    "    # \n",
    "    replace_price_range = {'$': 1, '$$ - $$$': 2, '$$$$':4}\n",
    "    df_output['price'] = df_output['price'].map(replace_price_range)\n",
    "    \n",
    "    \n",
    "    df_output['Number_of_Reviews_isNAN'] = pd.isna(df_output['number_of_reviews']).astype('uint8')\n",
    "    \n",
    "    # \n",
    "    df_output['number_of_reviews'] = df_output.groupby(\"city\")['number_of_reviews'].transform(\n",
    "        lambda x: x.fillna(x.mean()))\n",
    "    \n",
    "    \n",
    "    \n",
    "    Cuisine_x = df_output['URL']\n",
    "    Cuisine_number = Cuisine_x.explode()\n",
    "    \n",
    "    \n",
    "    # \n",
    "    URL_limit = 2\n",
    "    URL_cnts = Cuisine_number.value_counts()\n",
    "    URL_columns = list(URL_cnts[URL_cnts > URL_limit].index)\n",
    "    Other_columns = list(set(URL_cnts.index) - set(URL_columns))\n",
    "    \n",
    "    \n",
    "    for URL in URL_columns:\n",
    "        df_output[URL] = df_output['URL'].astype(\n",
    "            'str').apply(lambda x: 1 if URL in x else 0)\n",
    "\n",
    "\n",
    "    def other_URL(URL_str):\n",
    "        for URL in Other_columns:\n",
    "            if URL in URL_str:\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    \n",
    "\n",
    "    df_output['ID'] = df_output['ID'].apply(lambda x: int(x[1:]))\n",
    "    \n",
    "    \n",
    "    # ################### 3. Encoding ############################################################## \n",
    "    df_output = pd.get_dummies(df_output, columns=['city'], dummy_na=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # ################### 5. Clean #################################################### \n",
    "    # убираем признаки которые еще не успели обработать, \n",
    "    # модель на признаках с dtypes \"object\" обучаться не будет, просто выберим их и удалим\n",
    "    object_columns = [s for s in df_output.columns if df_output[s].dtypes == 'object']\n",
    "    df_output.drop(object_columns, axis = 1, inplace=True)\n",
    "    \n",
    "    return df_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">По хорошему, можно было бы перевести эту большую функцию в класс и разбить на подфункции (согласно ООП). Но по моему опыту я только слышал про это, но пока это не проходили, далее в обучении освою ООП)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запускаем и проверяем что получилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc = preproc_data(data)\n",
    "df_preproc.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preproc.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь выделим тестовую часть\n",
    "train_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\n",
    "test_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n",
    "\n",
    "y = train_data.Rating.values            # наш таргет\n",
    "X = train_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \n",
    "Это поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Воспользуемся специальной функцией train_test_split для разбивки тестовых данных\n",
    "# выделим 20% данных на валидацию (параметр test_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем\n",
    "test_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model \n",
    "Сам ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортируем необходимые библиотеки:\n",
    "from sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\n",
    "from sklearn import metrics # инструменты для оценки точности модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\n",
    "model = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель на тестовом наборе данных\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n",
    "# Предсказанные значения записываем в переменную y_pred\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Округлим предсказанные значения до степени округления целевой переменной\n",
    "y_pred = np.round(y_pred*2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n",
    "# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\n",
    "print('MAE:', metrics.mean_absolute_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission\n",
    "Если все устраевает - готовим Submission на кагл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['Rating'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_submission = list(map(lambda x: round(x * 2)/2, predict_submission))\n",
    "predict_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['Rating'] = predict_submission\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
